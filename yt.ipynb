{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a95c8f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Chat Section\n",
    "# -------------------------\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "for msg in st.session_state.messages:\n",
    "    with st.chat_message(msg[\"role\"]):\n",
    "        st.markdown(msg[\"content\"])\n",
    "\n",
    "if \"video_id\" not in st.session_state:\n",
    "    st.info(\"üì∫ Please ingest a YouTube video first to start chatting.\")\n",
    "    st.stop()\n",
    "else:\n",
    "    if prompt := st.chat_input(\"Ask about this video...\"):\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(prompt)\n",
    "\n",
    "        try:\n",
    "            docs = query_qdrant(st.session_state.video_id, prompt, top_k=5)\n",
    "            # üí° DEBUG STEP: Display the retrieved documents\n",
    "            st.sidebar.subheader(\"Debugging: Retrieved Chunks\")\n",
    "            for i, d in enumerate(docs):\n",
    "                st.sidebar.write(f\"Chunk {i+1} Score: {d.metadata.get('score', 'N/A')}\")\n",
    "                st.sidebar.code(d.page_content[:250] + \"...\")\n",
    "            context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "            system_prompt = (\n",
    "            \"You are a helpful assistant that answers questions about YouTube videos. \"\n",
    "            \"Use only the provided transcript context to answer clearly and naturally. \"\n",
    "            \"Do NOT mention technical details or metadata. \"\n",
    "            \"If you don't know the answer, say you don't know and don't hallucinate.\"\n",
    "            )\n",
    "\n",
    "            user_prompt = f\"Transcript Context:\\n{context}\\n\\nQuestion: {prompt}\"\n",
    "\n",
    "            with st.chat_message(\"assistant\"):\n",
    "                with st.spinner(\"Thinking...\"):\n",
    "                    answer = call_openrouter(system_prompt, \n",
    "                                             user_prompt, \n",
    "                                             api_key=os.environ.get(\"OPENROUTER_API_KEY\"))\n",
    "                    st.markdown(answer)\n",
    "\n",
    "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error during chat: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e4acd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math \n",
    "import streamlit as st\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled\n",
    "from langchain_openai import ChatOpenAI\n",
    "from deep_translator import GoogleTranslator\n",
    "from langchain_qdrant import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# -------------------------\n",
    "# Configuration & helpers\n",
    "# -------------------------\n",
    "OPENROUTER_API_KEY = os.environ.get(\"OPENROUTER_API_KEY\", None)\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "# OpenRouter endpoint & model - you can change model to whatever is available on your OpenRouter plan\n",
    "OPENROUTER_MODELS = [\"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
    "                    \"meta-llama/llama-3.2-3b-instruct:free\"]  \n",
    "\n",
    "# Embedding model (multilingual Minilm)\n",
    "EMBEDDING_MODEL = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "# Text splitting config\n",
    "COLLECTION_NAME = \"youtube_transcripts\"\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 80\n",
    "\n",
    "# Retrieval config\n",
    "TOP_K = 5\n",
    "\n",
    "# -----------------------------------\n",
    "# OpenRouter call helper\n",
    "# -----------------------------------\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "\n",
    "# ---- Streamlit callback for live updates ----\n",
    "class StreamHandler(BaseCallbackHandler):\n",
    "    def __init__(self, container):\n",
    "        self.container = container\n",
    "        self.text = \"\"\n",
    "\n",
    "    def on_llm_new_token(self, token, **kwargs):\n",
    "        self.text += token\n",
    "import time\n",
    "def call_openrouter(system_prompt: str, user_prompt: str, api_key: str,\n",
    "                    model: str = None, temperature: float = 0.7):\n",
    "    \"\"\"\n",
    "    Efficient wrapper for OpenRouter using LangChain's ChatOpenAI.\n",
    "    Uses the model selected in the sidebar unless overridden.\n",
    "    \"\"\"\n",
    "    if not api_key:\n",
    "        raise ValueError(\"‚ùå OPENROUTER_API_KEY not set. Please provide a valid API key.\")\n",
    "\n",
    "    # ‚úÖ Use sidebar model if not explicitly passed\n",
    "    #active_model = model or model_name\n",
    "\n",
    "    # ‚úÖ Stream container in UI\n",
    "    stream_container = st.empty()\n",
    "    handler = StreamHandler(stream_container)\n",
    "    \n",
    "    # ‚úÖ Initialize LLM\n",
    "    llm = ChatOpenAI(\n",
    "        model_name=model_name,\n",
    "        temperature=temperature,  # fixed temperature (not user-controlled)\n",
    "        openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "        openai_api_key=api_key,\n",
    "        streaming=True,\n",
    "        callbacks=[handler],  # üëà important\n",
    "        request_timeout=60,  # <‚Äî add this line                \n",
    "    )\n",
    "\n",
    "    # ‚úÖ Combine system + user messages\n",
    "    messages = [(\"system\", system_prompt), (\"user\", user_prompt)]\n",
    "\n",
    "    # ‚úÖ Generate completion\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # ‚úÖ Just invoke to trigger streaming, but don‚Äôt print returned content again\n",
    "    llm.invoke(messages)\n",
    "\n",
    "    # ‚úÖ Only return the streamed text\n",
    "    return handler.text\n",
    "\n",
    "# -------------------------\n",
    "# YouTube Transcript Helpers \n",
    "# -------------------------\n",
    "\n",
    "def extract_video_id(url: str) -> str:\n",
    "    \"\"\"Extract YouTube video ID from any URL pattern.\"\"\"\n",
    "    regex = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n",
    "    match = re.search(regex, url)\n",
    "    if not match:\n",
    "        st.error(\"‚ùå Invalid YouTube URL. Could not extract video ID.\")\n",
    "        raise ValueError(\"Invalid YouTube URL\")\n",
    "    return match.group(1)\n",
    "\n",
    "# ... (Your extract_video_id function here) ...\n",
    "\n",
    "def get_transcript_in_english(video_id: str):\n",
    "    \"\"\"\n",
    "    Fetch transcript for given video_id.\n",
    "    If English not found, auto-translates to English using batch translation \n",
    "    and shows a progress bar.\n",
    "    \"\"\"\n",
    "    ytt_api = YouTubeTranscriptApi()\n",
    "\n",
    "    try:\n",
    "        st.info(\"üéß Trying to fetch English transcript...\")\n",
    "        # Try to fetch English directly\n",
    "        transcript_list = ytt_api.fetch(video_id, languages=[\"en\"])\n",
    "        st.success(\"‚úÖ English transcript found.\")\n",
    "        # Return in the desired format\n",
    "        return [\n",
    "            {\"text\": t.text, \"start\": t.start, \"duration\": t.duration}\n",
    "            for t in transcript_list\n",
    "        ]\n",
    "\n",
    "    except NoTranscriptFound:\n",
    "        try:\n",
    "            st.warning(\"‚ö†Ô∏è English transcript not found. Looking for other languages...\")\n",
    "            available = ytt_api.list(video_id)\n",
    "            if not available:\n",
    "                st.error(\"‚ùå No transcripts found for this video.\")\n",
    "                return None\n",
    "\n",
    "            first_transcript = list(available)[0]\n",
    "            lang = first_transcript.language_code\n",
    "            st.warning(f\"Found transcript in '{lang}'. Fetching...\")\n",
    "            \n",
    "            # This 'transcript' is a list of FetchedTranscriptSnippet objects\n",
    "            transcript = first_transcript.fetch() \n",
    "            total_lines = len(transcript)\n",
    "\n",
    "            st.info(f\"üåê Translating {total_lines} lines from '{lang}' to English...\")\n",
    "            \n",
    "            # --- START OF NEW PROGRESS/BATCHING LOGIC ---\n",
    "            \n",
    "            # 1. Initialize progress bar and final list\n",
    "            progress_text = \"Translation starting...\"\n",
    "            progress_bar = st.progress(0, text=progress_text)\n",
    "            translated_transcript = []\n",
    "            \n",
    "            # 2. Set chunk size and translator\n",
    "            translator = GoogleTranslator(source=\"auto\", target=\"en\")\n",
    "            chunk_size = 100  # Translate 50 lines at a time\n",
    "            num_chunks = math.ceil(total_lines / chunk_size)\n",
    "\n",
    "            # 3. Loop over the *original* transcript list in chunks\n",
    "            for i in range(0, total_lines, chunk_size):\n",
    "                # Calculate progress\n",
    "                percent_complete = (i / total_lines)\n",
    "                progress_text = f\"Translating chunk {i//chunk_size + 1} of {num_chunks}... ({int(percent_complete * 100)}%)\"\n",
    "                progress_bar.progress(percent_complete, text=progress_text)\n",
    "\n",
    "                # Get the chunk of *objects*\n",
    "                transcript_chunk = transcript[i : i + chunk_size]\n",
    "                \n",
    "                # Get the text *from* that chunk\n",
    "                texts_to_translate = [t.text for t in transcript_chunk if hasattr(t, 'text')]\n",
    "\n",
    "                if not texts_to_translate:\n",
    "                    # This chunk had no text, just skip it\n",
    "                    continue\n",
    "                \n",
    "                # Translate this chunk\n",
    "                translated_texts = translator.translate_batch(texts_to_translate)\n",
    "                \n",
    "                # Rebuild this chunk with original timings\n",
    "                text_index = 0\n",
    "                for t in transcript_chunk:\n",
    "                    if hasattr(t, 'text'):\n",
    "                        translated_transcript.append({\n",
    "                            \"text\": translated_texts[text_index],\n",
    "                            \"start\": t.start,\n",
    "                            \"duration\": t.duration,\n",
    "                        })\n",
    "                        text_index += 1\n",
    "            \n",
    "            # 4. Clean up\n",
    "            progress_bar.progress(1.0, text=\"Translation complete!\")\n",
    "            progress_bar.empty() # Remove the progress bar after completion\n",
    "            \n",
    "            st.success(\"‚úÖ Transcript translated to English.\")\n",
    "            return translated_transcript\n",
    "\n",
    "        except Exception as e:\n",
    "            st.error(f\"‚ùå Failed to fetch or translate transcript: {e}\")\n",
    "            if 'progress_bar' in locals(): # Remove progress bar on error\n",
    "                progress_bar.empty()\n",
    "            return None\n",
    "\n",
    "    except TranscriptsDisabled:\n",
    "        st.error(\"üö´ Transcripts are disabled for this video.\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"‚ùå Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcript_to_documents(transcript, video_id):\n",
    "    \"\"\"Convert transcript data into LangChain Document objects.\"\"\"\n",
    "    if not transcript:\n",
    "        st.error(\"‚ùå No transcript available.\")\n",
    "        return None\n",
    "\n",
    "    full_text = \" \".join([t[\"text\"] for t in transcript if t.get(\"text\")])\n",
    "    return [Document(page_content=full_text, metadata={\"video_id\": video_id})]\n",
    "\n",
    "# -------------------------\n",
    "# Vector DB helpers\n",
    "# -------------------------\n",
    "def ingest_to_qdrant(video_id, youtube_url, transcript):\n",
    "    \"\"\"Split transcript, embed it, and upload to Qdrant with metadata.\"\"\"\n",
    "    if not transcript:\n",
    "        st.error(\"‚ùå No transcript available.\")\n",
    "        return None\n",
    "\n",
    "    client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
    "\n",
    "    # Prepare data\n",
    "    full_text = \" \".join([t[\"text\"] for t in transcript])\n",
    "    docs = [Document(page_content=full_text, metadata={\"video_id\": video_id, \"source\": youtube_url})]\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "    # 2. CREATE COLLECTION & INGEST DATA\n",
    "    Qdrant.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        url=QDRANT_URL,\n",
    "        api_key=QDRANT_API_KEY,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "    )\n",
    "    \n",
    "def query_qdrant(video_id, query_text, top_k=5):\n",
    "    \"\"\"Retrieve top-k chunks for a given video_id and query text.\"\"\"\n",
    "    client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "    vectorstore = Qdrant(\n",
    "        client=client,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        embeddings=embeddings,\n",
    "    )\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": top_k},\n",
    "    )\n",
    "\n",
    "    results = retriever.invoke(query_text)\n",
    "    return results\n",
    "\n",
    "# -------------------------\n",
    "# Streamlit UI\n",
    "# -------------------------\n",
    "st.set_page_config(page_title=\"YouTube Transcript Chatbot\", layout=\"wide\", page_icon=\"üé¨\")\n",
    "\n",
    "st.markdown(\n",
    "    \"<h1 style='text-align:center;'>üé¨ YouTube Transcript Chatbot</h1>\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "\n",
    "st.markdown(\n",
    "    \"<h3 style='text-align: center;'>Chat with your YouTube Video's</h3>\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "\n",
    "with st.sidebar:\n",
    "    st.header(\"‚öôÔ∏è Settings\")\n",
    "\n",
    "    # ‚úÖ Define friendly display names mapped to full OpenRouter IDs\n",
    "    MODEL_OPTIONS = {\n",
    "        \" Meta LLaMA 3.2-Instruct\": \"meta-llama/llama-3.2-3b-instruct:free\",\n",
    "        \"Mistral Small-Instruct\": \"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
    "    }\n",
    "\n",
    "    # ‚úÖ Show friendly names in dropdown\n",
    "    display_name = st.selectbox(\n",
    "        \"Select Model\",\n",
    "        list(MODEL_OPTIONS.keys()),\n",
    "        index=0,\n",
    "    )\n",
    "\n",
    "    # ‚úÖ Use full model ID internally\n",
    "    model_name = MODEL_OPTIONS[display_name]\n",
    "\n",
    "    youtube_url = st.text_input(\"Enter YouTube Video URL\",placeholder=\"https://www.youtube.com/watch?v=...\")\n",
    "    ingest_btn = st.button(\"Ingest Transcript\", key=\"ingest_btn\")\n",
    "\n",
    "    if ingest_btn:\n",
    "        if not youtube_url.strip():\n",
    "            st.warning(\"Please enter a valid YouTube URL.\")\n",
    "        else:\n",
    "            # üëá Entire process now lives inside sidebar spinner\n",
    "            with st.spinner(\"‚è≥ Fetching and preparing transcript...\"):\n",
    "                try:\n",
    "                    video_id = extract_video_id(youtube_url)\n",
    "\n",
    "                    # Run transcript + translation fully in sidebar\n",
    "                    transcript = get_transcript_in_english(video_id)\n",
    "\n",
    "                    if transcript:\n",
    "                        from langchain_core.documents import Document\n",
    "                        full_text = \" \".join([t[\"text\"] for t in transcript])\n",
    "                        docs = [Document(page_content=full_text, metadata={\"video_id\": video_id, \"source\": youtube_url})]\n",
    "\n",
    "                        ingest_to_qdrant(video_id, youtube_url, transcript)\n",
    "                        st.session_state[\"video_id\"] = video_id  # ‚úÖ store for chat\n",
    "                        st.session_state[\"youtube_url\"] = youtube_url\n",
    "                        st.success(\"‚úÖ Transcript ingested and stored successfully.\")\n",
    "                        st.write(\"üé¨ Video ID:\", video_id)\n",
    "                        st.code(full_text[:600] + \" ...\")\n",
    "\n",
    "                    else:\n",
    "                        st.error(\"‚ùå Failed to fetch or translate transcript.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Error during ingestion: {e}\")\n",
    "\n",
    "# -------------------------\n",
    "# Chat Section\n",
    "# -------------------------\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "for msg in st.session_state.messages:\n",
    "    with st.chat_message(msg[\"role\"]):\n",
    "        st.markdown(msg[\"content\"])\n",
    "\n",
    "if \"video_id\" not in st.session_state:\n",
    "    st.info(\"üì∫ Please ingest a YouTube video first to start chatting.\")\n",
    "    st.stop()\n",
    "else:\n",
    "    if prompt := st.chat_input(\"Ask about this video...\"):\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(prompt)\n",
    "\n",
    "        try:\n",
    "            docs = query_qdrant(st.session_state.video_id, prompt, top_k=5)\n",
    "            # üí° DEBUG STEP: Display the retrieved documents\n",
    "            st.sidebar.subheader(\"Debugging: Retrieved Chunks\")\n",
    "            for i, d in enumerate(docs):\n",
    "                st.sidebar.write(f\"Chunk {i+1} Score: {d.metadata.get('score', 'N/A')}\")\n",
    "                st.sidebar.code(d.page_content[:250] + \"...\")\n",
    "            context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "            system_prompt = (\n",
    "            \"You are a helpful assistant that answers questions about YouTube videos. \"\n",
    "            \"Use only the provided transcript context to answer clearly and naturally. \"\n",
    "            \"Do NOT mention technical details or metadata. \"\n",
    "            \"If you don't know the answer, say you don't know and don't hallucinate.\"\n",
    "            )\n",
    "\n",
    "            user_prompt = f\"Transcript Context:\\n{context}\\n\\nQuestion: {prompt}\"\n",
    "\n",
    "            with st.chat_message(\"assistant\"):\n",
    "                with st.spinner(\"Thinking...\"):\n",
    "                    answer = call_openrouter(system_prompt, \n",
    "                                             user_prompt, \n",
    "                                             api_key=os.environ.get(\"OPENROUTER_API_KEY\"))\n",
    "                    st.markdown(answer)\n",
    "\n",
    "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error during chat: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
